{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d64de137110469d8a8c667f41222577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3af02cf889d944ee82ae35c6856e343c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e81cdf8933194d75a0c1e8f3bb9599fb",
              "IPY_MODEL_a1ce7063f6d54e99bddd7176b44dc1ee"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "3af02cf889d944ee82ae35c6856e343c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "e81cdf8933194d75a0c1e8f3bb9599fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bd9952b78dec4da096188aa96083dc75",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 71,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 71,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25541dc631494202a9985f06b6116d1d"
          },
          "model_module_version": "1.5.0"
        },
        "a1ce7063f6d54e99bddd7176b44dc1ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ad40c9390a346a8bc0d2dd1daa78e39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 71/71 [01:30&lt;00:00,  1.27s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f4de1ebc2624db2a3e3c7c5b7dba5bb"
          },
          "model_module_version": "1.5.0"
        },
        "bd9952b78dec4da096188aa96083dc75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "25541dc631494202a9985f06b6116d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "5ad40c9390a346a8bc0d2dd1daa78e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "9f4de1ebc2624db2a3e3c7c5b7dba5bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBLZjxZLgP3u"
      },
      "source": [
        "### **Inital setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd4NZAq7LeH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c66698-b9f4-4b3f-b0d1-d132d52757a0"
      },
      "source": [
        "# Install TFOD API (TF 2)\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "%cd models/research\n",
        "!pip install --upgrade pip\n",
        "\n",
        "# Compile protos.\n",
        "\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Install TensorFlow Object Detection API.\n",
        "\n",
        "!cp object_detection/packages/tf1/setup.py .\n",
        "!python -m pip install --use-feature=2020-resolver ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "2.12.0\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 87279, done.\u001b[K\n",
            "remote: Counting objects: 100% (1033/1033), done.\u001b[K\n",
            "remote: Compressing objects: 100% (489/489), done.\u001b[K\n",
            "remote: Total 87279 (delta 606), reused 928 (delta 533), pack-reused 86246\u001b[K\n",
            "Receiving objects: 100% (87279/87279), 599.23 MiB | 34.35 MiB/s, done.\n",
            "Resolving deltas: 100% (62488/62488), done.\n",
            "/content/models/research\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.2.1\n",
            "\n",
            "Usage:   \n",
            "  /usr/bin/python3 -m pip install [options] <requirement specifier> [package-index-options] ...\n",
            "  /usr/bin/python3 -m pip install [options] -r <requirements file> [package-index-options] ...\n",
            "  /usr/bin/python3 -m pip install [options] [-e] <vcs project url> ...\n",
            "  /usr/bin/python3 -m pip install [options] [-e] <local project path> ...\n",
            "  /usr/bin/python3 -m pip install [options] <archive url/path> ...\n",
            "\n",
            "option --use-feature: invalid choice: '2020-resolver' (choose from 'fast-deps', 'truststore', 'no-binary-enable-wheel-cache')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWprg3OxgS7o"
      },
      "source": [
        "### **Gather trained model and test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qim1npNwMqkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be18ed3e-3a44-4ed1-f63e-726fa9a69c75"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJp4Z1IINvUq"
      },
      "source": [
        "!wget -q https://storage.googleapis.com/open_source_datasets/ShelfImages.tar.gz\n",
        "!tar xf ShelfImages.tar.gz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6HgPU9HNx7X",
        "outputId": "2136da19-aba3-42f1-99e1-65cb80589899"
      },
      "source": [
        "!ls -lh ShelfImages/test | head -10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 101M\n",
            "-rw-r--r-- 1 1001 1001 1.6M Oct 23  2019 C1_P02_N1_S5_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 2.3M Oct 23  2019 C1_P02_N2_S2_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 2.3M Oct 23  2019 C1_P02_N2_S3_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 1.3M Oct 23  2019 C1_P03_N1_S2_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 1.6M Oct 23  2019 C1_P03_N1_S3_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 2.4M Oct 23  2019 C1_P03_N1_S4_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 1.4M Oct 23  2019 C1_P03_N1_S4_2.JPG\n",
            "-rw-r--r-- 1 1001 1001 1.1M Oct 23  2019 C1_P03_N2_S2_1.JPG\n",
            "-rw-r--r-- 1 1001 1001 1.7M Oct 23  2019 C1_P03_N2_S3_1.JPG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnDZPmbYgXOo"
      },
      "source": [
        "### **Other imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75QByXOZN2Ea"
      },
      "source": [
        "from imutils import paths\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j007Jtg-gZ1C"
      },
      "source": [
        "### **Image parsing utility**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuDYf5L8T9QU"
      },
      "source": [
        "def parse_image(image_path: str) -> np.ndarray:\n",
        "    \"\"\"Reads an image and adds a batch dimension.\"\"\"\n",
        "    image = plt.imread(image_path).astype(np.uint8)\n",
        "    image = np.expand_dims(image, 0)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4t2CTblgxJX"
      },
      "source": [
        "### **Load test image paths**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlUGjLG8PWOD",
        "outputId": "db021e78-8b1c-4d64-f92a-a9094d722962"
      },
      "source": [
        "test_image_paths = list(paths.list_images(\"ShelfImages/test\"))\n",
        "test_image_paths[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ShelfImages/test/C2_P03_N2_S3_1.JPG',\n",
              " 'ShelfImages/test/C1_P10_N1_S5_1.JPG',\n",
              " 'ShelfImages/test/C3_P01_N2_S3_2.JPG',\n",
              " 'ShelfImages/test/C4_P03_N1_S3_1.JPG',\n",
              " 'ShelfImages/test/C2_P04_N3_S2_1.JPG']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi4aiGlxgzOZ"
      },
      "source": [
        "### **Load detection graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lK3FyaXOSx5"
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(\"frozen_inference_graph.pb\", \"rb\") as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VKMB60rhbit"
      },
      "source": [
        "### **Inference utility**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMKP9-KaPNzf"
      },
      "source": [
        "def run_inference_for_single_image(image, graph, min_threshold=0.6):\n",
        "    \"\"\"Runs detection graph on an image and parses the results.\"\"\"\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                \"num_detections\", \"detection_boxes\", \"detection_scores\",\n",
        "                \"detection_classes\"]:\n",
        "                tensor_name = key + \":0\"\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "                image_tensor = tf.get_default_graph().get_tensor_by_name(\"image_tensor:0\")\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                    feed_dict={image_tensor: image})\n",
        "\n",
        "    # Post-process the results\n",
        "    output_dict[\"detection_scores\"] = output_dict[\"detection_scores\"][0]\n",
        "    mask = output_dict[\"detection_scores\"] > min_threshold\n",
        "\n",
        "    return output_dict[\"detection_scores\"][mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4m2vMjZhelj"
      },
      "source": [
        "### **Run bulk inference and prepare JSON file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "9d64de137110469d8a8c667f41222577",
            "3af02cf889d944ee82ae35c6856e343c",
            "e81cdf8933194d75a0c1e8f3bb9599fb",
            "a1ce7063f6d54e99bddd7176b44dc1ee",
            "bd9952b78dec4da096188aa96083dc75",
            "25541dc631494202a9985f06b6116d1d",
            "5ad40c9390a346a8bc0d2dd1daa78e39",
            "9f4de1ebc2624db2a3e3c7c5b7dba5bb"
          ]
        },
        "id": "m2n5B338eFOM",
        "outputId": "7876012c-1d81-4a45-c168-8557a3f94516"
      },
      "source": [
        "image_to_products = {}\n",
        "for image_path in tqdm(test_image_paths):\n",
        "    image_name = image_path.split(\"/\")[-1]\n",
        "    image = parse_image(image_path)\n",
        "    num_products = len(run_inference_for_single_image(image, detection_graph))\n",
        "    image_to_products[image_name] = num_products\n",
        "\n",
        "json_string = json.dumps(image_to_products, indent=4)\n",
        "with open(\"image2products.json\", \"w\") as outfile:\n",
        "    outfile.write(json_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d64de137110469d8a8c667f41222577",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=71.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkBhSZZ3fhyY",
        "outputId": "c16304f5-03a1-4fa3-90cc-901e3e1d6e60"
      },
      "source": [
        "!head -10 image2products.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"C2_P03_N2_S3_1.JPG\": 22,\n",
            "    \"C1_P10_N1_S5_1.JPG\": 51,\n",
            "    \"C3_P01_N2_S3_2.JPG\": 17,\n",
            "    \"C4_P03_N1_S3_1.JPG\": 33,\n",
            "    \"C2_P04_N3_S2_1.JPG\": 21,\n",
            "    \"C3_P03_N2_S4_1.JPG\": 49,\n",
            "    \"C3_P04_N1_S5_1.JPG\": 40,\n",
            "    \"C4_P08_N2_S2_1.JPG\": 24,\n",
            "    \"C4_P03_N1_S4_1.JPG\": 45,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebooks takes the model trained in `Colabs/GroceryDataset_Model_Training.ipynb` notebook and runs inference with it to determine how many products are likely to be present inside a given shelf image."
      ],
      "metadata": {
        "id": "5P1AufNJUEts"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C62tMvqf0hb"
      },
      "source": [
        "## References\n",
        "* https://github.com/anirbankonar123/CorrosionDetector/blob/master/rust_localization.ipynb"
      ]
    }
  ]
}